---------1.6-------------
1.实现多分词
2.允许多个词库文件
3.单字的单位独立一个文件(data/units.dic, 已经放入jar包里)
---------1.5-------------
1.使用sogou核心词库(15W)
2.把chars.dic文件放到jar里, 我们不需要关心他
3.最长匹配遍历调整(基本不受长词的影响)
4.优化了程序,除去没有必要的数组复制等,性能提升40%
---------1.0.2------------
1.数字接着的年月日独立分
---------1.0.1------------
1.MMSeg.next() 断句有个 bug。
空白字符后面的英文会丢失，且分词停止。

如：“手机电子书 http”空格后面的http丢了。

---------1.0--------------
1.实现 mmseg 算法分词
2.有两种 Simple 和 Complex 分词
3.扩展 Lucene 的 Analyzer, 以便结合 Lucene 使用
4.扩展 Solr 的 TokenizerFactory, 以便结合 Solr 使用